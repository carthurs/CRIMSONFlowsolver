/*! \file reduced_order_unscented_kalman_filter.dox
    \brief Reduced Order Unscented Kalman Filter.
*/

/*!
\page reduced_order_unscented_kalman_filter Reduced Order Unscented Kalman Filter

Verdandi provides a C++ implementation of the reduced order unscented Kalman filter (ROUKF), which is the generalized formulation of the singular evolutive interpolated Kalman filter (SEIK).

The reduced order unscented Kalman filter (ROUKF) is implemented in <code>ReducedOrderUnscentedKalmanFilter.hxx</code> and <code>ReducedOrderUnscentedKalmanFilter.cxx</code>. The class \link Verdandi::ReducedOrderUnscentedKalmanFilter ReducedOrderUnscentedKalmanFilter\endlink is a template class: <code>ReducedOrderUnscentedKalmanFilter<T, ClassModel, ClassObservationManager></code>. <code>T</code> is the type of the elements to be stored (e.g. <code>double</code>), <code>ClassModel</code> is the type of the model (e.g. <code>ClampedBar<double></code>), <code>ClassObservationManager</code> is the type of the observation manager (e.g. <code>LinearObservationManager<double></code>).

A simulation with the reduced order unscented Kalman filter (ROUKF) may be carried
out with the following C++ lines:

\precode
ReducedOrderUnscentedKalmanFilter<real, ClampedBar<real>,
        LinearObservationManager<real> > driver; [1]

driver.Initialize(argv[1]); [2]

while (!driver.HasFinished()) [6]
{
    driver.InitializeStep(); [3]

    driver.Forward(); [4]

    driver.Analyze(); [5]
}
\endprecode

\comment
  <li> First build the \link Verdandi::ReducedOrderUnscentedKalmanFilter ReducedOrderUnscentedKalmanFilter\endlink driver with the construction \link Verdandi::ReducedOrderUnscentedKalmanFilter::ReducedOrderUnscentedKalmanFilter() ReducedOrderUnscentedKalmanFilter\endlink. </li>

  <li> Then initialize the driver, the model and the observation manager, and read option keys in the configuration file with \link Verdandi::ReducedOrderUnscentedKalmanFilter::Initialize(string configuration_file, bool initialize_model, bool initialize_observation_manager) Initialize(configuration_file)\endlink. This optionally computes an analysis with the model initial condition. </li>

  <li> Optionally intialize a step with \link Verdandi::ReducedOrderUnscentedKalmanFilter::InitializeStep() InitializeStep()\endlink. This initializes a step for the model. </li>

  <li> Perform a step forward and propagate the state error variance with \link Verdandi::ReducedOrderUnscentedKalmanFilter::Forward() Forward()\endlink. </li>

  <li> Compute the analysis with \link Verdandi::ReducedOrderUnscentedKalmanFilter::Analyze() Analyze()\endlink, whenever observations are available. </li>

  <li> Compute the data assimilation until the model has finished: \link Verdandi::ReducedOrderUnscentedKalmanFilter::HasFinished() HasFinished()\endlink returns true if the simulation is done, false otherwise. </li>
\endcomment


\section algorithm5 Reduced Order Unscented Kalman filter algorithm

Assuming that P is of reduced rank p – typically much smaller than the dimension of the space n – the basic idea in
reduced-order ﬁltering is, in essence, to be able to manipulate covariance matrices in the factorized form
    \f[ P = LU^{-1}L^{T}, \f]

where U – in the group of invertible matrices \f$\mathcal{GL}_{p}\f$ – is of much smaller size than P \f$\in \mathcal{M}_{n}\f$ and represents the
main uncertainties in the system. What is crucial here is to be able to perform all computations on L and U
without needing to compute P.

\section algorithm6 Simplex case

In this section, we focus on the simplex distribution.
Consider some simplex sigma-points \f$ (V^{(i)})_{1\leq i \leq r} \in \mathbb{R}^p \f$ associated with some coeﬃcients \f$ (\alpha) = ( \alpha_1 ... \alpha_r )^T \f$. Then, we deﬁne the matrix of
these sigma-points denoted by \f$ [V^{*}] \in \mathcal{M}_{r,p}\f$ and the matrix \f$ D_{\alpha} = diag( \alpha_1 ... \alpha_r ) \in \mathcal{M}_{r}\f$.

<ol>
            <li>Sampling:
            - \f$ C_{h} = \sqrt{U_h^{-1}} \f$,<br>
            - \f$ x_{h}^{(i)a} = x_h^a + L_hC_hI^{(i)} \textrm{, } \quad 1\leq i \leq p+1 \f$<br>
            </li>
            <li>Prediction:
            - \f$ x_{h+1}^f = E_\alpha(\mathcal{M}_{h}(x_{h+1}^{(*)a})) \f$<br>
            - \f$ x_{h+1}^{(i)f} =  \left|
            \begin{array}{ll}
			x_{h+1}^f + [\mathcal{M}_{h}(x_{h}^{*a})]D_\alpha [V^*]^T ([V^*] D_\alpha [V^*]^T)^{-1/2}I^{(i)}& \textrm{with  resampling} \\
			\textrm{or} & \\
			\mathcal{M}_{h}(x_{h}^{(i)a}) & \textrm{without resampling}
			\end{array}\right. \\ \f$
            - \f$ L_{h+1} = [x_{h+1}^{(*)f}]D_\alpha [V^*]^T \in \mathcal{M}_{n,p} \f$<br>
            - \f$ P_{h+1}^f = L_{h+1} (P_{\alpha}^V)^{-1} L_{h+1}^T \f$</li>
           <li>Update:
            - \f$ y_{h+1}^{(i)} = \mathcal{H}_{h+1}(x_{h+1}^{(i)f})\f$<br>
            - \f$ \{HL\}_{h+1} = [y_{h+1}^{*}]D_\alpha [V^*]^T\f$,<br>
            - \f$ U_{h+1} = P_{\alpha}^V +  \{HL\}_{h+1}^T R_{h+1}^{-1} \{HL\}_{h+1} \in \mathcal{M}_{p}\f$<br>
            - \f$ x_{h+1}^a = x_{h+1}^f + L_{h+1}U_{h+1}^{-1}\{HL\}_{h+1}^T R_{h+1}^{-1} (y_{h+1}-E_\alpha(y_{h+1}^{(*)}))\f$<br>
            - \f$ P_{h+1}^a =  L_{h+1} U_{h+1}^{-1} L_{h+1}^T\f$</li>
</ol>
With: <br>
\f$x_h^f\f$ forecast state vector; <br>
\f$x_h^a\f$ analysis state vector; <br>
\f$y_h\f$ observation vector; <br>
\f$\mathcal{H}_h\f$ observation operator that maps the state space to the observation space; <br>
\f$H_h\f$ observation operator linearized at \f$x^f_h\f$; <br>
\f$P^f_h\f$ error covariance matrix of \f$x_h^f\f$; <br>
\f$P^a_h\f$ error covariance matrix of \f$x_h^a\f$; <br>
\f$R_h\f$ observational error covariance matrix; <br>
\f$\mathcal{M}_h\f$ model.

It is worthwhile noting that the SEIK filter is equivalent to this reduced UKF algorithm. In fact, the SEIK procedure uses in the resampling and covariance factorization a matrix which is nothing but the transposed of [V ∗] with this particular choice of sigma-points.


\section algorithm7 Generalized case

Given adequate sampling rules, precompute the corresponding
\f$[V^*]\f$, \f$P_{\alpha}^V = [V^*] D_\alpha [V^*]^T \f$, \f$[I^*] = ([V^*] D_\alpha [V^*]^T)^{-\frac{1}{2}} [V^*]\f$, and \f$D_V = D_\alpha [V^*]^T  (P_{\alpha}^V))^{-1} [V^*] D_\alpha \f$.

<ol>
            <li>Sampling:
            - \f$ C_{h} = \sqrt{U_h^{-1}} \f$<br>
            - \f$ x_{h}^{(i)a} = x_h^a + L_hC_hI^{(i)} \textrm{, } \quad 1\leq i \leq p+1 \f$<br>
            </li>
            <li>Prediction:
            - \f$ x_{h+1}^f = E_\alpha(\mathcal{M}_{h}(x_{h+1}^{(*)a})) \f$<br>
            - \f$ x_{h+1}^{(i)f} = x_{h+1}^f + [\mathcal{M}_{h}(x_{h}^{*a}) - x_{h+1}^f]D_{\alpha}^{1/2} \Upsilon_p I^(i), \textrm{ resampling with SVD} \f$<br>
            - \f$ L_{h+1} = [x_{h+1}^{(*)f}]D_\alpha [V^*]^T \in \mathcal{M}_{n,p} \f$<br>
            - \f$ P_{h+1}^f = L_{h+1} (P_{\alpha}^V)^{-1} L_{h+1}^T \f$</li>
           <li>Update:
            - \f$ [\tilde{y}] = [\mathcal{H}_{h+1}(x_{h+1}^{(*)f}) - E_\alpha(\mathcal{H}_{h+1}(x_{h+1}^{(*)f})) ]\f$<br>
            - \f$ D_m = [\tilde{y}]^T R_{h+1}^{-1}[\tilde{y}] \in \mathcal{M}_r \f$<br>
            - \f$ U_{h+1}  = P_{\alpha}^V + [V^*] D_\alpha \bigl(1 + D_m(D_\alpha - D_V)\bigr)^{-1} D_m D_\alpha [V^*]^T \in \mathcal{M}_{p} \f$<br>
            - \f$ \{HL\}_{h+1} = [\tilde{y}]( 1 + D_\alpha D_m)^{-1}\Bigl(1 + D_V \bigl( 1+D_m (D_\alpha-D_V) \bigr)^{-1} D_m \Bigr) D_\alpha[V^*]^T \f$<br>
            - \f$ x_{h+1}^a = x_{h+1}^f + L_{h+1}U_{h+1}^{-1}\{HL\}_{h+1}^T R_{h+1}^{-1} (y_{h+1}-E_\alpha(y_{h+1}^{(*)}))\f$<br>
            - \f$ P_{h+1}^a =  L_{h+1} U_{h+1}^{-1} L_{h+1}^T\f$</li>
</ol>
With: <br>
\f$x_h^f\f$ forecast state vector; <br>
\f$x_h^a\f$ analysis state vector; <br>
\f$y_h\f$ observation vector; <br>
\f$\mathcal{H}_h\f$ observation operator that maps the state space to the observation space; <br>
\f$H_h\f$ observation operator linearized at \f$x^f_h\f$; <br>
\f$P^f_h\f$ error covariance matrix of \f$x_h^f\f$; <br>
\f$P^a_h\f$ error covariance matrix of \f$x_h^a\f$; <br>
\f$R_h\f$ observational error covariance matrix; <br>
\f$\mathcal{M}_h\f$ model.


\section ukf_ref Reference

For more detail about the reduced order unscented Kalman filtering see<br>
 <a href="http://dx.doi.org/10.1051/cocv/2010006" style="color:black">Reduced-order Unscented Kalman Filtering with application to parameter identification in large-dimensional systems (P. Moireau, D. Chapelle)</a>.

*/
